{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "#Conda environment python 3.12.10 chronos_project\n",
    "#Run as administrator\n",
    "\n",
    "#pip install datasets\n",
    "import datasets\n",
    "import pandas as pd \n",
    "#In Anaconda prompt: conda activate chronos_project\\ conda install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Database libraries\n",
    "from autogluon.timeseries import TimeSeriesPredictor\n",
    "import torch\n",
    "from chronos import BaseChronosPipeline\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "import random as rn\n",
    "\n",
    "#Progress bar\n",
    "from tqdm import tqdm\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pandas_streaming_all(ds: datasets.Dataset) -> pd.DataFrame:\n",
    "    \"\"\"Convierte todo el shard de un dataset en streaming a un DataFrame en formato 'long'.\n",
    "    \n",
    "    Se recolecta cada muestra del shard, se crea el DataFrame y se aplica explode\n",
    "    sobre las columnas que almacenan secuencias, para luego inferir los tipos de datos.\n",
    "    \"\"\"\n",
    "    # Colect all the samples in the shard\n",
    "    data_list = [sample for sample in tqdm(ds_split, desc=\"Procesando shard\")]\n",
    "    \n",
    "    #As the loading is with streaming, the data is not in a list, so we need to convert it to a list\n",
    "    df = pd.DataFrame(data_list)\n",
    "    \n",
    "    # Identtify sequence columns in the dataset\n",
    "    sequence_columns = [col for col in ds.features if isinstance(ds.features[col], datasets.Sequence)]\n",
    "    \n",
    "    #Apply explode to the sequence columns, so we divide every value in the sequence into a new row\n",
    "    for col in sequence_columns:\n",
    "        if col in df.columns:\n",
    "            df = df.explode(col)\n",
    "    \n",
    "    return df.infer_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6342894291dc48f4958944f0613dbd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load dataset\n",
    "#Training corpus with  10M TSMixup augmentations of real-world data\n",
    "ds = datasets.load_dataset(\n",
    "    \"autogluon/chronos_datasets\",\n",
    "    \"training_corpus_tsmixup_10m\",\n",
    "    streaming=True,\n",
    "    split=\"train\"\n",
    ")\n",
    "#ds.set_format(\"numpy\")\n",
    "  # sequences returned as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IterableDataset({\n",
      "    features: ['target', 'id', 'timestamp'],\n",
      "    num_shards: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#The data can be split it into 200 parts\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'id': Value(dtype='string', id=None), 'timestamp': Sequence(feature=Value(dtype='timestamp[ms]', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(ds.features)\n",
    "#Verify the type of data that the features have, all of them are concurrent to the description of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shard the dataset an take one part.\n",
    "ds_split = ds.shard(num_shards=200, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IterableDataset({\n",
      "    features: ['target', 'id', 'timestamp'],\n",
      "    num_shards: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shard0=pd.DataFrame(ds_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.613463059343371, 0.5711616398408842, 0.5182...</td>\n",
       "      <td>T0000000</td>\n",
       "      <td>[1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>T0000001</td>\n",
       "      <td>[1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.0770299311167582, 4.308119724467033, 1.0770...</td>\n",
       "      <td>T0000002</td>\n",
       "      <td>[1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.004624637833987918, 0.00547248810355237, 0....</td>\n",
       "      <td>T0000003</td>\n",
       "      <td>[1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.4764301971138915, 0.49643825495907135, 0.53...</td>\n",
       "      <td>T0000004</td>\n",
       "      <td>[1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.43618684847808536, 0.42986687631831216, 0.4...</td>\n",
       "      <td>T0000005</td>\n",
       "      <td>[1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[2.401216908955567, 2.4339980271665644, 2.4831...</td>\n",
       "      <td>T0000006</td>\n",
       "      <td>[1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.5051982397841839, 0.5233518735046003, 0.522...</td>\n",
       "      <td>T0000007</td>\n",
       "      <td>[1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.5321381187621922, 0.5171483125998776, 0.479...</td>\n",
       "      <td>T0000008</td>\n",
       "      <td>[1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-8.913489815619967e-06, -1.1187203725208862e-...</td>\n",
       "      <td>T0000009</td>\n",
       "      <td>[1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              target        id  \\\n",
       "0  [0.613463059343371, 0.5711616398408842, 0.5182...  T0000000   \n",
       "1  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...  T0000001   \n",
       "2  [1.0770299311167582, 4.308119724467033, 1.0770...  T0000002   \n",
       "3  [0.004624637833987918, 0.00547248810355237, 0....  T0000003   \n",
       "4  [0.4764301971138915, 0.49643825495907135, 0.53...  T0000004   \n",
       "5  [0.43618684847808536, 0.42986687631831216, 0.4...  T0000005   \n",
       "6  [2.401216908955567, 2.4339980271665644, 2.4831...  T0000006   \n",
       "7  [0.5051982397841839, 0.5233518735046003, 0.522...  T0000007   \n",
       "8  [0.5321381187621922, 0.5171483125998776, 0.479...  T0000008   \n",
       "9  [-8.913489815619967e-06, -1.1187203725208862e-...  T0000009   \n",
       "\n",
       "                                           timestamp  \n",
       "0  [1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...  \n",
       "1  [1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...  \n",
       "2  [1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...  \n",
       "3  [1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...  \n",
       "4  [1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...  \n",
       "5  [1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...  \n",
       "6  [1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...  \n",
       "7  [1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...  \n",
       "8  [1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...  \n",
       "9  [1970-01-01 00:00:00, 1970-01-01 01:00:00, 197...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shard0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   target     50000 non-null  object\n",
      " 1   id         50000 non-null  object\n",
      " 2   timestamp  50000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_shard0.info()\n",
    "#Originally, the dataset has 50.000 timeseries, whith a sequence of more than 1.000 values each one.\n",
    "#As we need process each value as a new row, we will use just a sample to be able to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose a random raw to compare characteristics\n",
    "a=rn.randint(0,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_shard0[\"target\"][0])==len(df_shard0[\"target\"][a]) \n",
    "#Not all the sequences have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_shard0[\"target\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the dataset to a pandas dataframe -> long format\n",
    "df_shard0 = to_pandas_streaming_all(ds_split)\n",
    "#Save df_shard0 to csv\n",
    "#df_shard0.to_csv(\"df_shard0.csv\", index=False)\n",
    "#As this corpus is too big, it is preferable to work with a smaller databse such as m4_daily to run the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M4 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema from the dataset follows the next structure: \n",
    "\n",
    "* Each dataset row corresponds to a single (univariate or multivariate) time series.\n",
    "\n",
    "* There exists one column with name id and type string that contains the unique identifier of each time series.\n",
    "\n",
    "* There exists one column of type Sequence with dtype timestamp[ms]. This column contains the timestamps of the observations. Timestamps are guaranteed to have a regular frequency that can be obtained with pandas.infer_freq.\n",
    "\n",
    "* There exists at least one column of type Sequence with numeric (float, double, or int) dtype. These columns can be interpreted as target time series.\n",
    "\n",
    "* For each row, all columns of type Sequence have same length. Remaining columns of types other than Sequence (e.g., string or float) can be interpreted as static covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database M4: \n",
    "This dataset is a collection of 100,000 time series used for the fourth edition of the Makridakis forecasting Competition. The M4 dataset consists of time series of yearly, quarterly, monthly and other (weekly, daily and hourly) data, which were used as part of the training corpus of the Chronos model.\n",
    "\n",
    "https://paperswithcode.com/dataset/m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e39c40704004ae095702e749b59911f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/65.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1f37688b6d442dbae9f3e9f5b0aa3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4227 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"autogluon/chronos_datasets\", \"m4_daily\", split=\"train\")\n",
    "ds.set_format(\"numpy\")  # sequences returned as numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'timestamp', 'target', 'category'],\n",
      "    num_rows: 4227\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': Value(dtype='string', id=None), 'timestamp': Sequence(feature=Value(dtype='timestamp[ms]', id=None), length=-1, id=None), 'target': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'category': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(ds.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format(\"numpy\")  # sequences returned as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pandas(ds: datasets.Dataset) -> \"pd.DataFrame\":\n",
    "    \"\"\"Convert dataset to long data frame format.\"\"\"\n",
    "    sequence_columns = [col for col in ds.features if isinstance(ds.features[col], datasets.Sequence)]\n",
    "    return ds.to_pandas().explode(sequence_columns).infer_objects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_df= to_pandas(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000000</td>\n",
       "      <td>1994-03-01 12:00:00</td>\n",
       "      <td>1017.1</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000000</td>\n",
       "      <td>1994-03-02 12:00:00</td>\n",
       "      <td>1019.3</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000000</td>\n",
       "      <td>1994-03-03 12:00:00</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000000</td>\n",
       "      <td>1994-03-04 12:00:00</td>\n",
       "      <td>1019.2</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000000</td>\n",
       "      <td>1994-03-05 12:00:00</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000000</td>\n",
       "      <td>1994-03-06 12:00:00</td>\n",
       "      <td>1015.6</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000000</td>\n",
       "      <td>1994-03-07 12:00:00</td>\n",
       "      <td>1018.5</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000000</td>\n",
       "      <td>1994-03-08 12:00:00</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000000</td>\n",
       "      <td>1994-03-09 12:00:00</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T000000</td>\n",
       "      <td>1994-03-10 12:00:00</td>\n",
       "      <td>1021.5</td>\n",
       "      <td>Macro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           timestamp  target category\n",
       "0  T000000 1994-03-01 12:00:00  1017.1    Macro\n",
       "0  T000000 1994-03-02 12:00:00  1019.3    Macro\n",
       "0  T000000 1994-03-03 12:00:00  1017.0    Macro\n",
       "0  T000000 1994-03-04 12:00:00  1019.2    Macro\n",
       "0  T000000 1994-03-05 12:00:00  1018.7    Macro\n",
       "0  T000000 1994-03-06 12:00:00  1015.6    Macro\n",
       "0  T000000 1994-03-07 12:00:00  1018.5    Macro\n",
       "0  T000000 1994-03-08 12:00:00  1018.3    Macro\n",
       "0  T000000 1994-03-09 12:00:00  1018.4    Macro\n",
       "0  T000000 1994-03-10 12:00:00  1021.5    Macro"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   object\n",
       "timestamp    datetime64[ns]\n",
       "target              float64\n",
       "category             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_df.dtypes \n",
    "#The datatype od the timestamp is adequate just as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAta type of id\n",
    "#Data type of category\n",
    "#How many categories do we have\n",
    "#How many id, do we have? \n",
    "#It is the same id corresponding to the same category? \n",
    "#Does exist null data? \n",
    "#Are there all the days in the timestamp? or\n",
    "#  do we need to rpoduce null data to the sequences? \n",
    "#How is the behavior of the timestamp: graph the current timestamp\n",
    "#cu√°l es el inicio y el final del timestamp? \n",
    "#How many values do we have in the target?\n",
    "\n",
    "#How do I need to pass the data to chronos? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnlp_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
